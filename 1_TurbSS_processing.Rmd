---
title: "TurbSS Processing"
author: "John Kemper"
date: "10/17/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


library(googledrive)
library(tidyverse)
library(ggplot2)
library(lubridate)
library(xts)
library(ggthemes)
library(readxl)
library(tools)
library(fs)
library(stringr)
library(purrr)
library(raster)
library(dygraphs)

```


##Data download from Google Drive
```{r}
###Specify the drive using the drive URL
turb_drive <- drive_get("https://drive.google.com/drive/u/1/folders/13K-gaXcBkCkLl1TTBw2tVQCjwsAUvSIW/")

###List files on drive
files <- drive_ls(turb_drive)

###Extract only the data files
excelFiles <- files %>%
  filter(str_detect(name, ".xlsx")) 

###Function to download the files from Drive and put them in a data folder
turb_download <- function(x, y) {
  drive_download(as_id(x), overwrite = TRUE)
  
  file_move(y, "C:/Users/jkemper/Documents/UrbanSediment/DRSediment/data")
  
  
}


###Download and store the files
map2(excelFiles$id, excelFiles$name, turb_download)

```


###Get file parameters from file folders
```{r}

###Get data file names
turb_files <- list.files("data")


###Get station names
turb_file_names <- turb_files %>% str_split(., "\\.") %>%
  unlist() %>%
  str_subset(., "DR")

```

###Build station-by-station data file for full monitoring period
```{r}
##File manipulation


for(i in 1:length(turb_files)) {
  
  sheet_extractor <- function(strng){
    
  sheets <- excel_sheets(paste0("./data/", strng)) %>%
    str_extract("201.$") %>%
    .[!is.na(.)]
  
  print(sheets)
  

  }
  
  file_name_extractor <- function(srg) {
    
    turb_file_names <- srg %>% str_split(., "\\.") %>%
      unlist() %>%
      str_subset(., "DR")
    
  }
  
  print(turb_files[i])
  
  sheets <- sheet_extractor(turb_files[i])
  
  file_name_extractor(turb_files[i])
  
  tmp <- map(sheets, read_xlsx, path = (paste0("./data/", turb_files[i]))) %>%
    bind_rows() %>%
    as_tibble() %>%
    dplyr::select(1:17)
    
  
  write_csv(tmp, paste0("data/", turb_file_names[i], "_allyears.csv"))
  
}

```



###Function to read in data for each station
```{r}
setwd("C:/Users/jkemper/Documents/UrbanSediment/DRSediment")

###Fucntion to read in the data file and remove bad characters from column names
file_reader <- function(strng) {
  
  station <- read_csv(strng) %>%  
    rename_all(~str_replace_all(., " ", "_")) %>%
    rename_all(~str_remove_all(., "[\\( \\)<>-]")) %>%
    rename_all(~str_remove_all(., "__")) %>%
    rename_all(~str_remove_all(., "[/*^=]")) %>%
    rename(datetime = 1)
  
  return(station)
  
}
```

###Read-in the data
```{r}
###Read in the file for each station
DR5 <- file_reader("data/DR5_allyears.csv")
DR4 <- file_reader("data/DR4_allyears.csv")
DR3 <- file_reader("data/DR3_allyears.csv")
DR2 <- file_reader("data/DR2_allyears.csv")
DRKR <- file_reader("data/DRKR_allyears.csv")

```

###Functions to prep data for storm selection
```{r}
###Add columns that calculate the change in discharge over a variety of timesteps 
###This is important for picking storms
delta_calculator <- function(df) {
  
  df_turb <- df %>%
    dplyr::select(1:10) %>%
    filter(!is.na(datetime)) %>%
    rename(Discharge_LperS = 3) %>%
    filter(!is.na(Discharge_cfs)) %>%
    mutate(delta_turb_lag = abs(Discharge_cfs - lag(Discharge_cfs))) %>%
    mutate(delta_turb_lag = replace_na(delta_turb_lag, 0)) %>%
    mutate(delta_turb_lag2 = abs(Discharge_cfs - lag(Discharge_cfs, n = 2))) %>%
    mutate(delta_turb_lag2 = replace_na(delta_turb_lag2, 0)) %>%
    mutate(delta_turb_lead = abs(Discharge_cfs - lead(Discharge_cfs))) %>%
    mutate(delta_turb_lead = replace_na(delta_turb_lead, 0)) %>%
    mutate(delta_turb_lead2 = abs(Discharge_cfs - lead(Discharge_cfs, n = 2))) %>%
    mutate(delta_turb_lead2 = replace_na(delta_turb_lead2, 0)) %>%
    mutate(delta_turb_lead3 = abs(Discharge_cfs - lead(Discharge_cfs, n = 3))) %>%
    mutate(delta_turb_lead3 = replace_na(delta_turb_lead3, 0)) %>%
    mutate(delta_turb_lead6 = abs(Discharge_cfs - lead(Discharge_cfs, n = 6))) %>%
    mutate(delta_turb_lead6 = replace_na(delta_turb_lead6, 0)) %>%
    mutate(delta_turb_lead12 = abs(Discharge_cfs - lead(Discharge_cfs, n = 12))) %>%
    mutate(delta_turb_lead12 = replace_na(delta_turb_lead2, 0))
  
}
```

###Now, we prep and plot the raw data
```{r}
###Add delta discharge columns for each station
DR5_turb <- delta_calculator(DR5)
DR4_turb <- delta_calculator(DR4)
DR3_turb <- delta_calculator(DR3)
DR2_turb <- delta_calculator(DR2)
DRKR_turb <- delta_calculator(DRKR)

###Interactive plot
DR5_plot <- DR5_turb_test %>%
  xts(., select(-datetime),
      order.by = .$datetime) %>%
  dygraph(.)


```

###Functions to identify and select storms
```{r}
###Function that identifies storms based on the change in discharge over 5 timesteps
###If that change > 0.3, then it labels that row with a 1 (indicating a storm)
###If it is less than 0.3, then it lables that row with a 0 (indicating no storm)
storm_detector <- function(df) {
  
  w <- df$delta_turb_lag
  x <- df$delta_turb_lead
  y <- df$delta_turb_lag2
  z <- df$delta_turb_lead2
  
  ifelse((w > 1 | x > 1 | y > 1 | z > 1), 1, 0)
  

}

###Second pass function to fill in storm tails 
###Checks to see if another "storm" occurs within 2 hrs of the end of the last storm
###If so, it essentially knits the two together (because they're likely the same storm) by recoding it with a 1
storm_detector_2 <- function(df) {
  
  a <- lag(df$code)
  b <- lag(df$code, 2)
  c<- lag(df$code, 4)
  
  d <- df$code
  
  j <- abs(df$datetime - lead(df$datetime))
  
  z <- lead(df$code)
  zz <- lead(df$code, n =4)
  zzz <- lead(df$code, n = 6)
  
  
  
  ifelse((j == 30 &  d == 0 & (a == 1 | b == 1 | c == 1) & (z == 1 | zz == 1 | zzz == 1)), 1, df$code)
}


###Third pass function to fill in storm tails tailored especially for 5 minute data
###Checks if there is a > 0.1 change in discharge within an hour of the end of the current storm
###This essentially ensures that storms with long flat tails are selected as one storm
###and not accidentally seperated
storm_detector_3 <- function(df) {
  
  a <- lag(df$code2, n = 12)
  b <- lag(df$code2, n = 24)
  c <- df$code2
  
  j <- abs(df$datetime - lead(df$datetime))
  
  w <- df$delta_turb_lag
  x <- df$delta_turb_lead
  y <- df$delta_turb_lag2
  
  z <- df$delta_turb_lead3
  zz <- df$delta_turb_lead6
  zzz <- df$delta_turb_lead12
  
  
 
  ifelse((j == 5 & (a == 1 | b == 1) & c == 0 & (w > 0.1 | x > 0.1 | y > 0.1 | z > 0.1 | zz > 0.1 | zzz > 0.1)), 
         1, df$code2)
}

###Fourth pass function to fully fill in the tails of storms in  5 minute data
###Checks to see if another "storm" occurs within an hours of the end of the current storm
###And knits the two together since, again, they're likely the same storm
###This is important because the third pass would seperate a double peaked storm where each peak has a long-ish tail
storm_detector_4 <- function(df) {
  
  a <- lag(df$code3, n = 3) 
  b <- lag(df$code3, n = 6) 
  c <- lag(df$code3, n = 12) 
  d <- lag(df$code3, n =24)
  e <- df$code3
  
  j <- abs(df$datetime - lead(df$datetime))
  
  z <- lead(df$code3, n = 3)
  zz <- lead(df$code3, n = 6)
  zzz <- lead(df$code3, n = 12)
  
  ifelse((j == 5 & (a == 1 | b == 1 | c == 1 | d == 1) & e == 0 & (z == 1 | zz == 1 | zzz == 1)),
         1, df$code3)
  
}

###Detect the storms
###Code indicates whether there is a storm present
###Transform code to logical to make it more sensible to a reader
###line that begins mutate(Group) uses the difference function to detect when there is a change in 
###the isStorm condition (i.e. a change from FALSE to TRUE or vice versa)
###and then uses cumsum to add 1 to the value every time that change occurs
###So what we get is a numerical storm label, i.e. each row in the first storm has 2 in the Group column
###the second storm a 4, and so on
storm_selector <- function(df) {
  
  storms <- df %>%
    mutate(code = storm_detector(.)) %>%
    mutate(Date = date(datetime))
  
  storms <- storms %>%
    mutate(code2 = storm_detector_2(.))
    
  storms <- storms %>%
    mutate(code3 = storm_detector_3(.)) 
  
  storms <- storms %>%
    mutate(code4 = storm_detector_4(.)) %>%
    mutate(isStorm = (as.logical(code4))) %>%
    mutate(Group = cumsum(c(1,diff(isStorm) != 0))) %>%
    mutate(Storm = ifelse(((Group/2)%%1) != 0, 0, Group/2)) %>%
    filter(isStorm == TRUE)
  
  
  return(storms)
}
```

###Now, identify and select the storms
```{r}
DR5_storms <- storm_selector(DR5_turb)
DR4_storms <- storm_selector(DR4_turb)
DR3_storms <- storm_selector(DR3_turb)
DR2_storms <- storm_selector(DR2_turb)
DRKR_storms <- storm_selector(DRKR_turb)
```


###Function to clean adn nest the storm data
```{r}
###Nest each storm within a list of storms and do a final filter for tiny, tiny storms that prolly aren't storms
###Also filter storms where there are no turbidity data 
storm_nester <- function(df) {
  
  susp_sed <- str_subset(names(df), "Suspended_sediment_load_kg")
  
  storms_nest <- df %>%
    nest(-Storm) %>%
    mutate(points = map(data, ~length(.x$datetime))) %>%
    mutate(storm_length = map(data, ~(last(.x$datetime) - .x$datetime[1]))) %>%
    filter(storm_length >= 2 & storm_length < 24) %>%
    filter(points > 5) %>%
    filter(!is.na(map(data, ~(sum(.x[,susp_sed])))))
  
  return(storms_nest)
}
```

###Clean the storm data
```{r}
DR5_storms_nest <- storm_nester(DR5_storms)
DR4_storms_nest <- storm_nester(DR4_storms)
DR3_storms_nest <- storm_nester(DR3_storms)
DR2_storms_nest <- storm_nester(DR2_storms)
DRKR_storms_nest <- storm_nester(DRKR_storms)

```

###Function to unnest in order to calculate storm summary stats
```{r}
###Unnest for summary stats
storm_unnester <- function(df) {
  
  storms_unnest <- df %>%
    unnest(data)
  
  return(storms_unnest)
  
}
```

###Unnest data
```{r}
DR5_storms_unnest <- storm_unnester(DR5_storms_nest)
DR4_storms_unnest <- storm_unnester(DR4_storms_nest)
DR3_storms_unnest <- storm_unnester(DR3_storms_nest)
DR2_storms_unnest <- storm_unnester(DR2_storms_nest)
DRKR_storms_unnest <- storm_unnester(DRKR_storms_nest)

```

###Function to calculate some summary statistics for each storm
```{r}
###Calculate some storm stats
storm_stat_calculator <- function(df, num) {
  
  conc_col_name <- str_subset(names(df), "Suspended_sediment_concentration")
  yield_col_name <- str_subset(names(df), "Suspended_sediment_load_kg")
  
  storm_stats <- df %>%
    group_by(Storm) %>%
    summarise(Yield = sum(get(yield_col_name))/num,
            MaxQ = max(Discharge_mmd),
            MeanQ = mean(Discharge_mmd),
            MaxSSC = max(get(conc_col_name)),
            MeanSSC = mean(get(conc_col_name)),
            dQ_Q = ((max(Discharge_mmd) - Discharge_mmd[1])/Discharge_mmd[1])) %>%
    na.omit(Yield)
  
  return(storm_stats)
  
}
```

###Calculate some summary statistics for each storm
```{r}
DR5_storms_stats <- storm_stat_calculator(DR5_storms_unnest, 1.63)
DR4_storms_stats <- storm_stat_calculator(DR4_storms_unnest, 1.92)
DR3_storms_stats <- storm_stat_calculator(DR3_storms_unnest, 5.09)
DR2_storms_stats <- storm_stat_calculator(DR2_storms_unnest, 5.84)
DRKR_storms_stats <- storm_stat_calculator(DRKR_storms_unnest, 14.2)
```

###Create c-Q plots
####Create the folders the plots will go in
```{r}
###Make folders to put cQ plots
station_names <- turb_file_names %>%
  str_split( "_") %>%
  unlist() %>%
  str_subset("DR") %>%
  unique()

####Function to create folders
folder_maker <- function(strng) {
  
  folder_name <- paste0(strng, "_CQ_plots")
  
  dir_create(paste0("C:/Users/jkemper/Documents/UrbanSediment/", folder_name))
}

####Create folders
map(station_names, folder_maker)
```

###Now, a function to make the actual plots
```{r}
###Make CQ plots

####Function to make the plots
plot_maker <- function(df, strng) {
  
  conc_col_name <- str_subset(names(df), "Suspended_sediment_concentration")
  
  df %>%
    mutate(ticker = row_number(datetime)) %>%
    ggplot(aes(x = Discharge_cfs, y = get(conc_col_name), color = ticker)) +
    geom_point(size = 5, shape = 1, stroke = 2) +
    geom_path() +
    theme_few() +
    scale_color_gradientn(colours = viridis::plasma(10))
  
  name <- date(df$datetime[1])
  storm <- df$Group[1]
  
  
  ggsave(paste0(name,"_", storm, ".png"), path = paste0("C:/Users/jkemper/Documents/UrbanSediment/", strng, "_CQ_plots"))
  
}
```

####Finally, make the actual plots
```{r}
###Make the plots
map(DR5_storms_nest$data, ~plot_maker(df = .x, strng = "DR5"))
map(DR4_storms_nest$data, ~plot_maker(df = .x, strng = "DR4"))
map(DR3_storms_nest$data, ~plot_maker(df = .x, strng = "DR3"))
map(DR2_storms_nest$data, ~plot_maker(df = .x, strng = "DR2"))
map(DRKR_storms_nest$data, ~plot_maker(df = .x, strng = "DRKR"))


```

