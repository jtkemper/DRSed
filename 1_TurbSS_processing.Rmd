---
title: "TurbSS Processing"
author: "John Kemper"
date: "10/17/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


library(googledrive)
library(tidyverse)
library(ggplot2)
library(lubridate)
library(xts)
library(ggthemes)
library(readxl)
library(tools)
library(fs)
library(stringr)
library(purrr)
library(raster)

```


##Data download from Google Drive
```{r}
###Specify the drive using the drive URL
turb_drive <- drive_get("https://drive.google.com/drive/u/1/folders/13K-gaXcBkCkLl1TTBw2tVQCjwsAUvSIW/")

###List files on drive
files <- drive_ls(turb_drive)

###Extract only the data files
excelFiles <- files %>%
  filter(str_detect(name, ".xlsx")) 

###Function to download the files from Drive and put them in a data folder
turb_download <- function(x, y) {
  drive_download(as_id(x))
  
  file_move(y, "C:/Users/John/Documents/DR Sediment/DRSediment/data/")
  
  
}

###Download and store the files
map2(excelFiles$id, excelFiles$name, turb_download)


###Get data file names
turb_files <- list.files("data")

###Get station names
turb_file_names <- turb_files %>% str_split(., "\\.") %>%
  unlist() %>%
  str_subset(., "DR")
 
###Extract all sheets
sheets <- excel_sheets(paste0("./data/", turb_files[3])) %>%
  str_extract("201.$") %>%
  .[!is.na(.)]


y <- map(sheets, read_xlsx, path = (paste0("./data/", turb_files[3])))




map(excel_sheets(path), read_excel, path = path)

```


```{r}
##File manipulation


DR_list <- list()

for(i in 1:length(turb_files)) {
  
  sheet_extractor <- function(lzt){
    
  sheets <- excel_sheets(paste0("./data/", lzt[i])) %>%
    str_extract("201.$") %>%
    .[!is.na(.)]
  
  return(sheets)

  }
  
  sheets <- sheet_extractor(turb_files[i])
  
  tmp <- map(sheets, read_xlsx, path = (paste0("./data/", turb_files[i])))
  
  
  DR_list[[i]] <- tmp
  
  
}
View(DR_list)
```

